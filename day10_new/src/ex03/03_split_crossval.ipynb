{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99abc204",
   "metadata": {},
   "source": [
    "# Day 08. Exercise 03\n",
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041ab2e",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c88d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56169460",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867adbe",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`.\n",
    "3. Using, for example, `value_counts()` to check if the distribution of classes is similar in train and test.\n",
    "4. Use the additional parameter `stratify=` and check the distribution again, now it should be more or less similar in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8db5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>uid_user_16</th>\n",
       "      <th>uid_user_17</th>\n",
       "      <th>uid_user_18</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid_user_1  uid_user_10  uid_user_11  uid_user_12  uid_user_13  \\\n",
       "0            0.0          0.0          0.0          0.0          0.0   \n",
       "1            0.0          0.0          0.0          0.0          0.0   \n",
       "2            0.0          0.0          0.0          0.0          0.0   \n",
       "3            0.0          0.0          0.0          0.0          0.0   \n",
       "4            0.0          0.0          0.0          0.0          0.0   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1681         0.0          0.0          0.0          0.0          0.0   \n",
       "1682         1.0          0.0          0.0          0.0          0.0   \n",
       "1683         1.0          0.0          0.0          0.0          0.0   \n",
       "1684         1.0          0.0          0.0          0.0          0.0   \n",
       "1685         1.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "      uid_user_14  uid_user_15  uid_user_16  uid_user_17  uid_user_18  ...  \\\n",
       "0             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "2             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "3             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "4             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "1681          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1682          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1683          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1684          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1685          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "\n",
       "      labname_lab05s  labname_laba04  labname_laba04s  labname_laba05  \\\n",
       "0                0.0             0.0              0.0             0.0   \n",
       "1                0.0             0.0              0.0             0.0   \n",
       "2                0.0             0.0              0.0             0.0   \n",
       "3                0.0             0.0              0.0             0.0   \n",
       "4                0.0             0.0              0.0             0.0   \n",
       "...              ...             ...              ...             ...   \n",
       "1681             0.0             0.0              0.0             0.0   \n",
       "1682             0.0             0.0              0.0             0.0   \n",
       "1683             0.0             0.0              0.0             0.0   \n",
       "1684             0.0             0.0              0.0             0.0   \n",
       "1685             0.0             0.0              0.0             0.0   \n",
       "\n",
       "      labname_laba06  labname_laba06s  labname_project1  numTrials      hour  \\\n",
       "0                0.0              0.0               1.0  -0.788667 -2.562352   \n",
       "1                0.0              0.0               1.0  -0.756764 -2.562352   \n",
       "2                0.0              0.0               1.0  -0.724861 -2.562352   \n",
       "3                0.0              0.0               1.0  -0.692958 -2.562352   \n",
       "4                0.0              0.0               1.0  -0.661055 -2.562352   \n",
       "...              ...              ...               ...        ...       ...   \n",
       "1681             0.0              1.0               0.0  -0.533442  0.945382   \n",
       "1682             0.0              1.0               0.0  -0.629151  0.945382   \n",
       "1683             0.0              1.0               0.0  -0.597248  0.945382   \n",
       "1684             0.0              1.0               0.0  -0.565345  0.945382   \n",
       "1685             0.0              1.0               0.0  -0.533442  0.945382   \n",
       "\n",
       "      dayofweek  \n",
       "0             4  \n",
       "1             4  \n",
       "2             4  \n",
       "3             4  \n",
       "4             4  \n",
       "...         ...  \n",
       "1681          3  \n",
       "1682          3  \n",
       "1683          3  \n",
       "1684          3  \n",
       "1685          3  \n",
       "\n",
       "[1686 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e853c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dayofweek'])\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d62553",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=21, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215c6e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "3    313\n",
       "6    287\n",
       "1    222\n",
       "5    216\n",
       "2    125\n",
       "0    105\n",
       "4     80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "569282df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "3    83\n",
       "6    69\n",
       "5    55\n",
       "1    52\n",
       "0    31\n",
       "4    24\n",
       "2    24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3d1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=21, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a9a105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "3    316\n",
       "6    285\n",
       "1    219\n",
       "5    217\n",
       "2    119\n",
       "0    109\n",
       "4     83\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "266a7459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dayofweek\n",
       "3    80\n",
       "6    71\n",
       "1    55\n",
       "5    54\n",
       "2    30\n",
       "0    27\n",
       "4    21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a5e8a",
   "metadata": {},
   "source": [
    "## 2. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc0d24",
   "metadata": {},
   "source": [
    "1. Train exactly the same baseline models from the previous exercise and calculate the accuracies using the test dataset with stratification.\n",
    "2. Did all the models show the similar values of the metric? Which one has the largest difference comparing the current exercise and the previous? Put the answer to the markdown cell in the end of the section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9a569",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d29133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "regr = LogisticRegression(random_state=21, fit_intercept=False, solver='liblinear')\n",
    "regr.fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4078a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769230769230769"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd31c39",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1b8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=21, probability=True, kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15828993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071005917159763"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cb938",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1215cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=21, max_depth=4)\n",
    "dtree.fit(X_train, y_train)\n",
    "pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a07b835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5295857988165681"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702c226f",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2a1b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor = RandomForestClassifier(random_state=21, max_depth=25, n_estimators=100)\n",
    "rfor.fit(X_train, y_train)\n",
    "pred = rfor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39929caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9378698224852071"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7e8e9",
   "metadata": {},
   "source": [
    "Random forest has 0.07 difference. Definitely overfitted previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422161a2",
   "metadata": {},
   "source": [
    "## 3. Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbc723",
   "metadata": {},
   "source": [
    "We could play with parameters of the model trying to achive a better accuracy on the test dataset, but it is a bad practice. It leads us again to overfitting. Test dataset is only for checking quality of a final model.\n",
    "\n",
    "But there is another way of solving the problem – crossvalidation. It does not use test dataset, but creates one more split of train dataset. Again, there are different ways of doing it, but the common thing is that there is a validation dataset that is used for hyperparameters optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca4634",
   "metadata": {},
   "source": [
    "1. Using `cross_val_score` with `cv=10` calculate the mean accuracy and standard deviation for every model that you used before (logreg with `solver='liblinear'`, SVC, decision tree, random forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f74eb0",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a90c264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vtsab\\DSB10_Intro_to_ML.ID_886521-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(regr, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2f97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.42210129613975766\n",
      "Standard deviation of accuracy: 0.1690565527135729\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f494c",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6cb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdf0d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.5057868413637645\n",
      "Standard deviation of accuracy: 0.14871599533216864\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d0865",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0835fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dtree, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ead601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.3883523527754297\n",
      "Standard deviation of accuracy: 0.11835394295385691\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27bd112",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94418cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfor, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ee7179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6601859678782754\n",
      "Standard deviation of accuracy: 0.16965550291752365\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3647ac",
   "metadata": {},
   "source": [
    "## 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991522a8",
   "metadata": {},
   "source": [
    "1. Choose the best model and play a little bit with the parameters on cross-validation, find a good enough parameter or a combination of the parameters.\n",
    "2. Calculate the accuracy for the final model on the test dataset.\n",
    "3. Draw a plot that displays the top-10 most  important features for that model.\n",
    "4. Save the model using `joblib`.\n",
    "5. Load the model, make predictions for the test dataset and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea9980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model):\n",
    "    '''\n",
    "    Получаем важность коэффициентов для разных моделей\n",
    "    '''\n",
    "    if hasattr(model, 'coef_'):\n",
    "        coef = model.coef_\n",
    "        # Если это матрица\n",
    "        if isinstance(coef, np.ndarray) and coef.ndim > 1:\n",
    "            importance = np.abs(coef).sum(axis=0)\n",
    "        else:\n",
    "            importance = np.abs(coef)\n",
    "        return importance\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        return model.feature_importances_\n",
    "    elif hasattr(model, 'estimators_'):\n",
    "        # Собираем важности\n",
    "        importance_list = []\n",
    "        for est in model.estimators_:\n",
    "            if hasattr(est, 'coef_'):\n",
    "                # Если есть coef_, суммируем по классам\n",
    "                coef = est.coef_\n",
    "                importance_list.append(np.abs(coef).sum(axis=0))\n",
    "            elif hasattr(est, 'feature_importances_'):\n",
    "                importance_list.append(est.feature_importances_)\n",
    "        # Складываем важности\n",
    "        return np.array(importance_list).sum(axis=0)\n",
    "    else:\n",
    "        raise ValueError('Не удалось получить коэффициенты модели')\n",
    "\n",
    "def plot_top_features(model, feature_names, top_n=10):\n",
    "    importance = get_feature_importance(model)\n",
    "    feature_importance = pd.Series(importance, index=feature_names)\n",
    "    top_features = feature_importance.nlargest(top_n)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    top_features.plot(kind='barh')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top {top_n} Features')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0573e926",
   "metadata": {},
   "source": [
    "RandomForest was the best, so let's play with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5b7bb",
   "metadata": {},
   "source": [
    "1. Base Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5828acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor1 = RandomForestClassifier(\n",
    "    random_state=21,\n",
    "    n_estimators=200,        # Увеличено количество деревьев\n",
    "    max_depth=15,            # Уменьшена глубина для борьбы с переобучением\n",
    "    min_samples_split=10,    # Минимальное количество samples для разделения узла\n",
    "    min_samples_leaf=4,      # Минимальное количество samples в листе\n",
    "    max_features='sqrt'      # Количество фичей для рассмотрения при разделении\n",
    ")\n",
    "rfor1.fit(X_train, y_train)\n",
    "pred = rfor1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b27dd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfor1, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14c32f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6110066215835446\n",
      "Standard deviation of accuracy: 0.1830916307897008\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc18dc5",
   "metadata": {},
   "source": [
    "2. Balanced to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd935c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor2 = RandomForestClassifier(\n",
    "    random_state=21,\n",
    "    n_estimators=150,\n",
    "    max_depth=10,            # Сильное ограничение глубины\n",
    "    min_samples_split=20,    # Более строгие требования для разделения\n",
    "    min_samples_leaf=10,     # Больше samples в терминальных узлах\n",
    "    max_samples=0.7,         # Использует только 70% данных для каждого дерева\n",
    "    bootstrap=True           # Включение бутстрап выборки\n",
    ")\n",
    "rfor2.fit(X_train, y_train)\n",
    "pred = rfor2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ae5853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfor2, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69ea182f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.47745843899690044\n",
      "Standard deviation of accuracy: 0.14720407317601888\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f28c2d",
   "metadata": {},
   "source": [
    "3. Balanced for maximized perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77929ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor3 = RandomForestClassifier(\n",
    "    random_state=21,\n",
    "    n_estimators=500,        # Большое количество деревьев\n",
    "    max_depth=None,          # Без ограничения глубины\n",
    "    min_samples_split=2,     # Минимальные ограничения\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',     # log2(n_features) для разделения\n",
    "    criterion='entropy'      # Альтернативный критерий для разделения\n",
    ")\n",
    "rfor3.fit(X_train, y_train)\n",
    "pred = rfor3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d673133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfor3, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6522f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6667089320935474\n",
      "Standard deviation of accuracy: 0.172302055333496\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb45a3",
   "metadata": {},
   "source": [
    "4. Balanced for Big Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3647ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor4 = RandomForestClassifier(\n",
    "    random_state=21,\n",
    "    n_estimators=50,         # Меньше деревьев для скорости\n",
    "    max_depth=8,             # Ограниченная глубина\n",
    "    min_samples_split=50,    # Крупные узлы для скорости\n",
    "    max_features=0.3,        # Меньше фичей для рассмотрения\n",
    "    n_jobs=-1,               # Использование всех ядер процессора\n",
    "    warm_start=False         # Не использовать предыдущую подгонку\n",
    ")\n",
    "rfor4.fit(X_train, y_train)\n",
    "pred = rfor4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15fe7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfor4, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d2bbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.4684770357847281\n",
      "Standard deviation of accuracy: 0.1440584540344384\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35295c87",
   "metadata": {},
   "source": [
    "4. Balanced for Big Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6044359",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor5 = RandomForestClassifier(\n",
    "    random_state=21,\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.5,        # 50% фичей для каждого разделения\n",
    "    ccp_alpha=0.01,          # Параметр минимальной cost-complexity pruning\n",
    "    oob_score=True           # Включение out-of-bag оценки\n",
    ")\n",
    "rfor5.fit(X_train, y_train)\n",
    "pred = rfor5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cf145b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfor5, X, y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "756a12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.4815828402366863\n",
      "Standard deviation of accuracy: 0.18237228354226606\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be16fb",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Third one (maximized perfomance) was the best, lets look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8f6b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_top_features(rfor, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd5373",
   "metadata": {},
   "source": [
    "### Save and load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd677a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rfor3, 'random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0f5fe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = joblib.load('random_forest_model.pkl')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
