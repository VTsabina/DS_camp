{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 02\n",
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
       "0          1     5         0.0         0.0          0.0          0.0   \n",
       "1          2     5         0.0         0.0          0.0          0.0   \n",
       "2          3     5         0.0         0.0          0.0          0.0   \n",
       "3          4     5         0.0         0.0          0.0          0.0   \n",
       "4          5     5         0.0         0.0          0.0          0.0   \n",
       "\n",
       "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
       "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
       "0             0.0             0.0             0.0              0.0   \n",
       "1             0.0             0.0             0.0              0.0   \n",
       "2             0.0             0.0             0.0              0.0   \n",
       "3             0.0             0.0             0.0              0.0   \n",
       "4             0.0             0.0             0.0              0.0   \n",
       "\n",
       "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
       "0             0.0             0.0              0.0               1.0   \n",
       "1             0.0             0.0              0.0               1.0   \n",
       "2             0.0             0.0              0.0               1.0   \n",
       "3             0.0             0.0              0.0               1.0   \n",
       "4             0.0             0.0              0.0               1.0   \n",
       "\n",
       "   dayofweek  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/day-of-week-not-scaled.csv')\n",
    "dayofweek = pd.read_csv('../data/dayofweek.csv')['dayofweek']\n",
    "df['dayofweek'] = dayofweek\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dayofweek'])\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the best parameters from the previous exercise and train the model of SVM.\n",
    "2. You need to calculate `accuracy`, `precision`, `recall`, `ROC AUC`.\n",
    "\n",
    " - `precision` and `recall` should be calculated for each class (use `average='weighted'`)\n",
    " - `ROC AUC` should be calculated for each class against any other class (all possible pairwise combinations) and then weighted average should be applied for the final metric\n",
    " - the code in the cell should display the result as below:\n",
    "\n",
    "```\n",
    "accuracy is 0.88757\n",
    "precision is 0.89267\n",
    "recall is 0.88757\n",
    "roc_auc is 0.97878\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_test, pred_proba, y_pred, mode='print'):\n",
    "    \n",
    "    # 1. Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 2. Precision и Recall (среднее по весам)\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # получаем количество классов\n",
    "    classes = np.unique(y_test)\n",
    "    # для каждого класса считаем ROC AUC против остальных\n",
    "    roc_auc_list = []\n",
    "    for i, class_label in enumerate(classes):\n",
    "        # двоичный вектор: положительный — этот класс, остальные — отрицательные\n",
    "        y_test_binary = (y_test == class_label).astype(int)\n",
    "        y_score = pred_proba[:, i]\n",
    "        try:\n",
    "            roc = roc_auc_score(y_test_binary, y_score)\n",
    "        except ValueError:\n",
    "            # если есть только один класс в y_test_binary\n",
    "            roc = np.nan\n",
    "        roc_auc_list.append(roc)\n",
    "    # взвешенное среднее по классам\n",
    "    # веса — доля каждого класса в y_test\n",
    "    class_counts = np.bincount(y_test)\n",
    "    total = len(y_test)\n",
    "    weights = class_counts / total\n",
    "    roc_auc = np.sum(np.array(roc_auc_list) * weights)\n",
    "    if mode == 'return':\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'roc_auc': roc_auc,\n",
    "        }\n",
    "    else:\n",
    "        # Вывод результатов\n",
    "        print(f\"accuracy is {accuracy:.5f}\")\n",
    "        print(f\"precision is {precision:.5f}\")\n",
    "        print(f\"recall is {recall:.5f}\")\n",
    "        print(f\"roc_auc is {roc_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.74556\n",
      "precision is 0.74827\n",
      "recall is 0.74556\n",
      "roc_auc is 0.93477\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state=21, kernel='linear', C=10, gamma='scale', probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "probas = svm.predict_proba(X_test)\n",
    "pred = svm.predict(X_test)\n",
    "compute_metrics(y_test, probas, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The same task for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.85207\n",
      "precision is 0.85574\n",
      "recall is 0.85207\n",
      "roc_auc is 0.93329\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=21, class_weight=None, criterion='entropy', max_depth=16)\n",
    "dtree.fit(X_train, y_train)\n",
    "probas = dtree.predict_proba(X_test)\n",
    "pred = dtree.predict(X_test)\n",
    "compute_metrics(y_test, probas, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The same task for random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.92012\n",
      "precision is 0.92304\n",
      "recall is 0.92012\n",
      "roc_auc is 0.98821\n"
     ]
    }
   ],
   "source": [
    "rfor = RandomForestClassifier(random_state=21, class_weight='balanced', criterion='entropy', max_depth=16, n_estimators=100)\n",
    "rfor.fit(X_train, y_train)\n",
    "probas = rfor.predict_proba(X_test)\n",
    "pred = rfor.predict(X_test)\n",
    "compute_metrics(y_test, probas, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model.\n",
    "2. Analyze: for which `weekday` your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which `labname` and for which `users`.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_names = {\n",
    "    0: \"Monday\",\n",
    "    1: \"Tuesday\",\n",
    "    2: \"Wednesday\",\n",
    "    3: \"Thursday\",\n",
    "    4: \"Friday\",\n",
    "    5: \"Saturday\",\n",
    "    6: \"Sunday\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most mistakes in class: Monday (22.22%)\n",
      "User with most errors: user_6 (50.00%)\n",
      "Lab with most errors: lab03 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y_test)\n",
    "users = [col[4:] for col in X_test.columns if col.startswith('uid')]\n",
    "labs = [col[8:] for col in X_test.columns if col.startswith('labname')]\n",
    "\n",
    "errors_per_class = {}\n",
    "errors_per_user = {}\n",
    "errors_per_lab = {}\n",
    "\n",
    "for cls in classes:\n",
    "    indices = np.where(y_test == cls)[0]\n",
    "    total_in_class = len(indices)\n",
    "    pred_in_class = pred[indices]\n",
    "    incorrect = np.sum(pred_in_class != cls)\n",
    "    error_percent = (incorrect / total_in_class) * 100 if total_in_class > 0 else 0\n",
    "    errors_per_class[cls] = error_percent\n",
    "\n",
    "for cls in classes:\n",
    "    # Создаём маску для объектов этого класса\n",
    "    class_mask = (y_test == cls)\n",
    "    total_in_class = np.sum(class_mask)\n",
    "\n",
    "    if total_in_class == 0:\n",
    "        error_percent = 0\n",
    "    else:\n",
    "        incorrect = np.sum((pred != cls) & class_mask)\n",
    "        error_percent = (incorrect / total_in_class) * 100\n",
    "\n",
    "    errors_per_class[cls] = error_percent\n",
    "\n",
    "# Анализ по пользователям\n",
    "for user in users:\n",
    "    col_name = 'uid_' + user\n",
    "    user_mask = X_test[col_name]\n",
    "    # Булева маска - где пользователь активен\n",
    "    boolean_mask = user_mask.astype(bool)\n",
    "    total = np.sum(boolean_mask)\n",
    "    if total > 0:\n",
    "        incorrect = np.sum((pred != y_test) & boolean_mask)\n",
    "        errors_per_user[user] = (incorrect / total) * 100\n",
    "    else:\n",
    "        errors_per_user[user] = 0\n",
    "\n",
    "# Анализ по лабораториям\n",
    "for lab in labs:\n",
    "    col_name = 'labname_' + lab\n",
    "    lab_mask = X_test[col_name]\n",
    "    boolean_mask = lab_mask.astype(bool)\n",
    "    total = np.sum(boolean_mask)\n",
    "    if total > 0:\n",
    "        incorrect = np.sum((pred != y_test) & boolean_mask)\n",
    "        errors_per_lab[lab] = (incorrect / total) * 100\n",
    "    else:\n",
    "        errors_per_lab[lab] = 0\n",
    "\n",
    "# Находим максимум\n",
    "most_error_pro_class = max(errors_per_class, key=errors_per_class.get)\n",
    "max_error_percentage = errors_per_class[most_error_pro_class]\n",
    "\n",
    "most_error_pro_user = max(errors_per_user, key=errors_per_user.get)\n",
    "max_error_user = errors_per_user[most_error_pro_user]\n",
    "\n",
    "most_error_pro_lab = max(errors_per_lab, key=errors_per_lab.get)\n",
    "max_error_lab = errors_per_lab[most_error_pro_lab]\n",
    "\n",
    "\n",
    "print(f\"Most mistakes in class: {day_names[most_error_pro_class]} ({max_error_percentage:.2f}%)\")\n",
    "print(f\"User with most errors: {most_error_pro_user} ({max_error_user:.2f}%)\")\n",
    "print(f\"Lab with most errors: {most_error_pro_lab} ({max_error_lab:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rfor, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that takes a list of different models and a corresponding list of parameters (dicts) and returns a dict that contains all the 4 metrics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, params, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    for model, param in zip(models, params):\n",
    "        # Инициализация модели с параметрами\n",
    "        model_instance = model(**param)\n",
    "        \n",
    "        # Обучение модели\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        \n",
    "        # Предсказания\n",
    "        y_pred = model_instance.predict(X_test)\n",
    "        y_proba = model_instance.predict_proba(X_test)\n",
    "        # Вычисление метрик\n",
    "        d = compute_metrics(y_test, y_proba, y_pred, mode='return')\n",
    "        \n",
    "        # сохраняем результаты\n",
    "        model_name = model.__name__\n",
    "        results[model_name] = d\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "    accuracy: 0.74556\n",
      "    precision: 0.74827\n",
      "    recall: 0.74556\n",
      "    roc_auc: 0.93477\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "    accuracy: 0.85207\n",
      "    precision: 0.85574\n",
      "    recall: 0.85207\n",
      "    roc_auc: 0.93329\n",
      "\n",
      "RandomForestClassifier:\n",
      "    accuracy: 0.92012\n",
      "    precision: 0.92304\n",
      "    recall: 0.92012\n",
      "    roc_auc: 0.98821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [SVC, DecisionTreeClassifier, RandomForestClassifier]\n",
    "params = [\n",
    "    {'random_state': 21, 'kernel': 'linear', 'C': 10, 'gamma': 'scale', 'probability': True},\n",
    "    {'random_state': 21, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 16},\n",
    "    {'random_state': 21, \"class_weight\": 'balanced', \"criterion\": 'entropy', \"max_depth\": 16, 'n_estimators': 100},\n",
    "    \n",
    "]\n",
    "\n",
    "results = evaluate_models(models, params, X_train, y_train, X_test, y_test)\n",
    "# print(results)\n",
    "for key, value in results.items():\n",
    "    print(f'{key}:')\n",
    "    for metric_key, metric_value in value.items():\n",
    "        print(f'    {metric_key}: {metric_value:.5f}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
