{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>uid_user_15</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
       "0          1     5         0.0         0.0          0.0          0.0   \n",
       "1          2     5         0.0         0.0          0.0          0.0   \n",
       "2          3     5         0.0         0.0          0.0          0.0   \n",
       "3          4     5         0.0         0.0          0.0          0.0   \n",
       "4          5     5         0.0         0.0          0.0          0.0   \n",
       "\n",
       "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
       "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
       "0             0.0             0.0             0.0              0.0   \n",
       "1             0.0             0.0             0.0              0.0   \n",
       "2             0.0             0.0             0.0              0.0   \n",
       "3             0.0             0.0             0.0              0.0   \n",
       "4             0.0             0.0             0.0              0.0   \n",
       "\n",
       "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
       "0             0.0             0.0              0.0               1.0   \n",
       "1             0.0             0.0              0.0               1.0   \n",
       "2             0.0             0.0              0.0               1.0   \n",
       "3             0.0             0.0              0.0               1.0   \n",
       "4             0.0             0.0              0.0               1.0   \n",
       "\n",
       "   dayofweek  \n",
       "0          4  \n",
       "1          4  \n",
       "2          4  \n",
       "3          4  \n",
       "4          4  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/day-of-week-not-scaled.csv')\n",
    "dayofweek = pd.read_csv('../data/dayofweek.csv')['dayofweek']\n",
    "df['dayofweek'] = dayofweek\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['dayofweek'])\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train1, y_train1, test_size=0.2, random_state=21, stratify=y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_test, y_pred, mode='print'):\n",
    "    \n",
    "    # 1. Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 2. Precision и Recall (среднее по весам)\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    if mode == 'return':\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "        }\n",
    "    elif mode == 'crosval':\n",
    "        print(f\"accuracy={accuracy:.5f} -- precision={precision:.5f} -- recall={recall:.5f}\")\n",
    "    else:\n",
    "        # Вывод результатов\n",
    "        print(f\"accuracy is {accuracy:.5f}\")\n",
    "        print(f\"precision is {precision:.5f}\")\n",
    "        print(f\"recall is {recall:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.69630\n",
      "precision is 0.69761\n",
      "recall is 0.69630\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state=21, kernel='linear', C=10, gamma='scale', probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "pred = svm.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.87407\n",
      "precision is 0.87393\n",
      "recall is 0.87407\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=21, class_weight=None, criterion='entropy', max_depth=16)\n",
    "dtree.fit(X_train, y_train)\n",
    "pred = dtree.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89630\n",
      "precision is 0.89660\n",
      "recall is 0.89630\n"
     ]
    }
   ],
   "source": [
    "rfor = RandomForestClassifier(random_state=21, class_weight='balanced', criterion='entropy', max_depth=16, n_estimators=100)\n",
    "rfor.fit(X_train, y_train)\n",
    "pred = rfor.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.88889\n",
      "precision is 0.88785\n",
      "recall is 0.88889\n"
     ]
    }
   ],
   "source": [
    "vc1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "vc1.fit(X_train, y_train)\n",
    "pred = vc1.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.87037\n",
      "precision is 0.87055\n",
      "recall is 0.87037\n"
     ]
    }
   ],
   "source": [
    "vc2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "vc2.fit(X_train, y_train)\n",
    "pred = vc2.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90370\n",
      "precision is 0.90333\n",
      "recall is 0.90370\n"
     ]
    }
   ],
   "source": [
    "vc3 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1,2,6],\n",
    "    flatten_transform=True\n",
    ")\n",
    "\n",
    "vc3.fit(X_train, y_train)\n",
    "pred = vc3.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89630\n",
      "precision is 0.89660\n",
      "recall is 0.89630\n"
     ]
    }
   ],
   "source": [
    "vc4 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='hard',\n",
    "    weights=[1,2,6],\n",
    "    flatten_transform=True\n",
    ")\n",
    "\n",
    "vc4.fit(X_train, y_train)\n",
    "pred = vc4.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90370\n",
      "precision is 0.90333\n",
      "recall is 0.90370\n"
     ]
    }
   ],
   "source": [
    "vc5 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1,2,6],\n",
    "    flatten_transform=False\n",
    ")\n",
    "\n",
    "vc5.fit(X_train, y_train)\n",
    "pred = vc5.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89630\n",
      "precision is 0.89660\n",
      "recall is 0.89630\n"
     ]
    }
   ],
   "source": [
    "vc6 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='hard',\n",
    "    weights=[1,2,6],\n",
    "    flatten_transform=False\n",
    ")\n",
    "\n",
    "vc6.fit(X_train, y_train)\n",
    "pred = vc6.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90370\n",
      "precision is 0.90333\n",
      "recall is 0.90370\n"
     ]
    }
   ],
   "source": [
    "vc7 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1,2,6],\n",
    "    flatten_transform=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "vc7.fit(X_train, y_train)\n",
    "pred = vc7.predict(X_valid)\n",
    "compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89349\n",
      "precision is 0.89501\n",
      "recall is 0.89349\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1,2,6],\n",
    ")\n",
    "\n",
    "vc.fit(X_train, y_train)\n",
    "pred = vc.predict(X_test)\n",
    "compute_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=10:\n",
      "accuracy is 0.70000\n",
      "precision is 0.72051\n",
      "recall is 0.70000\n",
      "n_estimators=20:\n",
      "accuracy is 0.68889\n",
      "precision is 0.71733\n",
      "recall is 0.68889\n",
      "n_estimators=30:\n",
      "accuracy is 0.66296\n",
      "precision is 0.67952\n",
      "recall is 0.66296\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in [10, 20, 30]:\n",
    "    bagging_clf = BaggingClassifier(\n",
    "        estimator=svm,\n",
    "        n_estimators=n_estimators, \n",
    "        random_state=21,\n",
    "        # n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    pred = bagging_clf.predict(X_valid)\n",
    "\n",
    "    print(f\"n_estimators={n_estimators}:\")\n",
    "    compute_metrics(y_valid, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=7:\n",
      "accuracy is 0.69259\n",
      "precision is 0.71620\n",
      "recall is 0.69259\n",
      "n_estimators=8:\n",
      "accuracy is 0.68889\n",
      "precision is 0.71042\n",
      "recall is 0.68889\n",
      "n_estimators=9:\n",
      "accuracy is 0.68519\n",
      "precision is 0.70878\n",
      "recall is 0.68519\n",
      "n_estimators=11:\n",
      "accuracy is 0.69259\n",
      "precision is 0.71382\n",
      "recall is 0.69259\n",
      "n_estimators=12:\n",
      "accuracy is 0.69259\n",
      "precision is 0.71710\n",
      "recall is 0.69259\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in [7, 8, 9, 11, 12]:\n",
    "    bagging_clf = BaggingClassifier(\n",
    "        estimator=svm,\n",
    "        n_estimators=n_estimators, \n",
    "        random_state=21,\n",
    "        # n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    bagging_clf.fit(X_train, y_train)\n",
    "    pred = bagging_clf.predict(X_valid)\n",
    "\n",
    "    print(f\"n_estimators={n_estimators}:\")\n",
    "    compute_metrics(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.72781\n",
      "precision is 0.75332\n",
      "recall is 0.72781\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(\n",
    "    estimator=svm,\n",
    "    n_estimators=10, \n",
    "    random_state=21,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "bc.fit(X_train, y_train)\n",
    "pred = bc.predict(X_test)\n",
    "\n",
    "compute_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits=2: \n",
      "accuracy is 0.89259\n",
      "precision is 0.89363\n",
      "recall is 0.89259\n",
      "\n",
      "splits=3: \n",
      "accuracy is 0.89259\n",
      "precision is 0.89283\n",
      "recall is 0.89259\n",
      "\n",
      "splits=4: \n",
      "accuracy is 0.90000\n",
      "precision is 0.89960\n",
      "recall is 0.90000\n",
      "\n",
      "splits=5: \n",
      "accuracy is 0.90000\n",
      "precision is 0.89943\n",
      "recall is 0.90000\n",
      "\n",
      "splits=6: \n",
      "accuracy is 0.90000\n",
      "precision is 0.90044\n",
      "recall is 0.90000\n",
      "\n",
      "splits=7: \n",
      "accuracy is 0.90000\n",
      "precision is 0.89943\n",
      "recall is 0.90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in [2, 3, 4, 5, 6, 7]:\n",
    "    print(f'splits={n}: ')\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=21)\n",
    "    stack = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('svc', svm),\n",
    "            ('dt', dtree), \n",
    "            ('rfor', rfor)\n",
    "        ],\n",
    "        cv=skf,\n",
    "        passthrough=False #default\n",
    "    )\n",
    "\n",
    "    stack.fit(X_train, y_train)\n",
    "    pred = stack.predict(X_valid)\n",
    "    compute_metrics(y_valid, pred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits=2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89259\n",
      "precision is 0.89396\n",
      "recall is 0.89259\n",
      "\n",
      "splits=3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89630\n",
      "precision is 0.89721\n",
      "recall is 0.89630\n",
      "\n",
      "splits=4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89259\n",
      "precision is 0.89262\n",
      "recall is 0.89259\n",
      "\n",
      "splits=5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.90741\n",
      "precision is 0.90746\n",
      "recall is 0.90741\n",
      "\n",
      "splits=6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89259\n",
      "precision is 0.89281\n",
      "recall is 0.89259\n",
      "\n",
      "splits=7: \n",
      "accuracy is 0.90370\n",
      "precision is 0.90370\n",
      "recall is 0.90370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for n in [2, 3, 4, 5, 6, 7]:\n",
    "    print(f'splits={n}: ')\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=21)\n",
    "    stack = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('svc', svm),\n",
    "            ('dt', dtree), \n",
    "            ('rfor', rfor)\n",
    "        ],\n",
    "        passthrough=True,\n",
    "        cv=skf,\n",
    "    )\n",
    "\n",
    "    stack.fit(X_train, y_train)\n",
    "    pred = stack.predict(X_valid)\n",
    "    compute_metrics(y_valid, pred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89941\n",
      "precision is 0.90067\n",
      "recall is 0.89941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vtsab\\DSB11_ML_Advanced.ID_886524-1\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svm),\n",
    "        ('dt', dtree), \n",
    "        ('rfor', rfor)\n",
    "    ],\n",
    "    passthrough=True,\n",
    "    cv=skf,\n",
    "    final_estimator=LogisticRegression(solver='liblinear'),\n",
    ")\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "pred = stack.predict(X_test)\n",
    "compute_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_names = {\n",
    "    0: \"Monday\",\n",
    "    1: \"Tuesday\",\n",
    "    2: \"Wednesday\",\n",
    "    3: \"Thursday\",\n",
    "    4: \"Friday\",\n",
    "    5: \"Saturday\",\n",
    "    6: \"Sunday\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most mistakes in class: Monday (25.93%)\n",
      "User with most errors: user_6 (25.00%)\n",
      "Lab with most errors: lab03 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "classes = np.unique(y_test)\n",
    "users = [col[4:] for col in X_test.columns if col.startswith('uid')]\n",
    "labs = [col[8:] for col in X_test.columns if col.startswith('labname')]\n",
    "\n",
    "errors_per_class = {}\n",
    "errors_per_user = {}\n",
    "errors_per_lab = {}\n",
    "\n",
    "for cls in classes:\n",
    "    indices = np.where(y_test == cls)[0]\n",
    "    total_in_class = len(indices)\n",
    "    pred_in_class = pred[indices]\n",
    "    incorrect = np.sum(pred_in_class != cls)\n",
    "    error_percent = (incorrect / total_in_class) * 100 if total_in_class > 0 else 0\n",
    "    errors_per_class[cls] = error_percent\n",
    "\n",
    "for cls in classes:\n",
    "    # Создаём маску для объектов этого класса\n",
    "    class_mask = (y_test == cls)\n",
    "    total_in_class = np.sum(class_mask)\n",
    "\n",
    "    if total_in_class == 0:\n",
    "        error_percent = 0\n",
    "    else:\n",
    "        incorrect = np.sum((pred != cls) & class_mask)\n",
    "        error_percent = (incorrect / total_in_class) * 100\n",
    "\n",
    "    errors_per_class[cls] = error_percent\n",
    "\n",
    "# Анализ по пользователям\n",
    "for user in users:\n",
    "    col_name = 'uid_' + user\n",
    "    user_mask = X_test[col_name]\n",
    "    # Булева маска - где пользователь активен\n",
    "    boolean_mask = user_mask.astype(bool)\n",
    "    total = np.sum(boolean_mask)\n",
    "    if total > 0:\n",
    "        incorrect = np.sum((pred != y_test) & boolean_mask)\n",
    "        errors_per_user[user] = (incorrect / total) * 100\n",
    "    else:\n",
    "        errors_per_user[user] = 0\n",
    "\n",
    "# Анализ по лабораториям\n",
    "for lab in labs:\n",
    "    col_name = 'labname_' + lab\n",
    "    lab_mask = X_test[col_name]\n",
    "    boolean_mask = lab_mask.astype(bool)\n",
    "    total = np.sum(boolean_mask)\n",
    "    if total > 0:\n",
    "        incorrect = np.sum((pred != y_test) & boolean_mask)\n",
    "        errors_per_lab[lab] = (incorrect / total) * 100\n",
    "    else:\n",
    "        errors_per_lab[lab] = 0\n",
    "\n",
    "# Находим максимум\n",
    "most_error_pro_class = max(errors_per_class, key=errors_per_class.get)\n",
    "max_error_percentage = errors_per_class[most_error_pro_class]\n",
    "\n",
    "most_error_pro_user = max(errors_per_user, key=errors_per_user.get)\n",
    "max_error_user = errors_per_user[most_error_pro_user]\n",
    "\n",
    "most_error_pro_lab = max(errors_per_lab, key=errors_per_lab.get)\n",
    "max_error_lab = errors_per_lab[most_error_pro_lab]\n",
    "\n",
    "\n",
    "print(f\"Most mistakes in class: {day_names[most_error_pro_class]} ({max_error_percentage:.2f}%)\")\n",
    "print(f\"User with most errors: {most_error_pro_user} ({max_error_user:.2f}%)\")\n",
    "print(f\"Lab with most errors: {most_error_pro_lab} ({max_error_lab:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StackingKFold.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "joblib.dump(stack, 'StackingKFold.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
